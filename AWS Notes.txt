S3 Service :- 

1. S3 is a object based storage.It allows u to upload files
2. S3 is not for block storage.U cannot install operaitng system or a database.
3. File size in S3 can be between 0 to 5 TB
4. S3 has unlimited storage.
5. Files are stored in buckets.Buckets are folders.
6. S3 buckets have universal namespace.Names of the buckets from be unique globally.
7. S3 bucket endpoint or URL convention is like - https://s3-<regionn>.amazonaws.com/<bucketname>
8. Read/Write consitancy
	8.1 Add Object - Read after write consistency for puts of new object.This means if u add a object and immediately try to access it.It ll be immediately availabe.
	8.2 Modify or Delete Object - Eventual consistency for overwrite puts and delete,It means once u modify or delete an object and then immediatey try to access it.It may or may not be reflected immediately.
9. Core fundamentals of S3.
	9.1 Key (name of the object)
	9.2 Value (Actual data)
	9.3 Version id
	9.4 Metadata (Data of data)
	9.5 Access control lists
10. Versioning
	10.1 Stores all versions of an object(Including all writes and even if u delete an object)
	10.2 You pay for each version of the object
	10.3 Great backup tool
	10.4 Once enabled cannont be disabled it can only be suspended.
	10.5 Versioning integrates with life cycle rules
	10.6 Versioning provides multi factor authentication delete capability to provide an additional layer of security

11 Cross region replication
	11.1 Requires versioning to be enabled on source bucket as well as on destination bucket.

12 Life cycle management 
	12.1 It can be used in conjuction wih versioning  or can be used independently
	12.2 Can be applied to all current versions and previous versions
	12.3 Rules for life cycle management 
		12.3.1 Transition to standard infrequent access - File size to more than or equal to 128 kb and 30 days after the date of creation
		12.3.2 Archive to glacier (30 days after moving into IA
		12.3.3 You can also permanently delete objects using life cycle management rules

13. Edge Location - Location where content is cached.This is seperate to AWS Region/AZ.Edge locations are not only read only.You can write or put object on them.Objects are cached in edge locations for TTL(Time to live).TTL is always secified in seconds.By default objects are cached for 24 hours.U can clear the cache but u ll be charged for that. 

14. Origin - THis is the origin of all files that CDN ll distribute.It can be S3,EC2,ELB or Route53
15. Distribution - THis is the name given to the CDN which consists of collection of Edge Locations
16. Types of distribution
	16.1 Web distribution (Typically used for websites)
	16.2 RTMP (Used for media streaming)

17. By default all newly creted buckets are private.
18. Access control on buckets 
	18.1 Bucket policies
	18.2 Access control list
19. S3 buckets can be confogured to create access logs.The logs can be logged in to another bucket of same account or any other account.
20. When u write successfully to S3 , you get http 200 response code
21. Files can be loaded in S3 faster by enabling multipart upload.
22. Read S3 FAQ  


* Storage Tiers/Classes
1. S3 (Durable,Immediately available , frequently accessed) Durability of 99.999999999%
2. S3 - IA(Infrequent Access) (Durable,Immediately available , Infrequently accessed) Durability of 99.999999999%
3. Reduced Redundancy Storage (RRS) (Data that is easily reproduciable like thumbnails.) Durability of 99.99%
4. Glacier (Not immediately available.Takes up to 3 to 5 hours before accessing.Cheapest storage tier.It is used to archive data)


* Storage Gateways
1. File Gateway (Only used for flat files.Not applicable for block storage like OS or databases.Nothing is stored on premises.Everything is stored on S3)
2. Storage valumes (Used for blocked and flat file storage.The entire dataset is stored in local on premises data center and async to S3 & EBS.Eg For a finance analytics company they need to have lowest possibe latency hence every thing is available locally and also the data is critical hence backed up in AWS cloud)
3. Cached Volumes (Used for block and flat file storage.The entire data set is stored on AWS EBS and S3.The most frequntly accessed data is then stored on premises data center.)
4. Gateway Virtual Tape Library (VTL are mostly used for backups and used popular backup applications like Net Backup, Backup exec ,Veeam etc) 


* Encrytion Types
	1. In Transit	
		1.1 SSL/TLS (HTTPS)
	2. At rest
		2.1 Server Side Encryption 
			2.1.1 SSE - S3 (Managed encryption keys by AWS.256 bit encryption)
			2.1.2 SSE - KMS (Key Management Service.Paid service.Provides envlope keys for encryption keys.Provision for logging to check who and when accessed the keys)
			2.1.3 SSE - C (Customer managed encryption keys.AWS does not manage the encryption keys.)
	3. Client side encryption - Encryption of data at client side then uploading the data in S3
	

* Snowball
	1. Types
		1.1 Standard Snowball - Snowball can import to S3 and export from S3.
		1.2 Snowball Edge - Not just storage capacity but compute capacity as well.Can run lama functions.Its a portable aws datacenter
		1.3 Snowmobile - Exabyte scale date transfer.100 Petabyte per snow mobile.

* Static website hosting
	1. Endpoint convention - https://<bucketname>.s3-website-<region>.amazonaws.com

Note :- Read S3 FAQs

**************************************************************************************************************************************************

EC2 Service :- 

1. Elastic Compute Cloud.Its the virtual servers in cloud of windows , linux etc
2. EC2 Options 
	2.1 On Demand - Allows u to pay fix rate by hour (or by second) with no commitment.Currently by seconds only for linux instances
	2.2 Reserved - Provides u with the capacity reservation , and offer a significant discount on hourly charges for an instance.1 year or 3 years term
		2.2.1 Standard RI (Reserved Instances) - Upto 75% off on demand
		2.2.2 Convertible RI (Reserve Instances) -  Upto 54% off on demand.Capability to change the attributes of he RIs as lonmg as the exchange results in he creation of reserved instances of equal or greater value.
		2.2.3 Scheduled RI (Reserved Instance) -  These are available to launch within the time windows u reserve.Allows u to match ur capacity reservation to a predictable recurring scheules that only requires a fraction of day , week or month
	2.3 Spot - Enables u to bid whatever price u want for instance capacity,providing for even greater savings if ur applications have flexible start and end times.
	2.4 Dedicated hosts - Physical EC2 server dedicated for ur use.It helps to reduce cost by allowing u to use your existing sever bound software licenses.
	2.5 Usecases for On Demand 
		2.5.1 Users who want low cost and flexibility if EC2
		2.5.2 Application with short term,spiky or unpredictable workloads that cannot be interrupted 
		2.5.3 Applications that are developed or tested on EC2 for the first time.
	2.6 Usecases for Reserved 
		2.6.1 Applications with steady state or predictable usage.
		2.6.2 Applications that require reserved capacity
		2.6.3 Users who are able to make upfront payments to further reduce computing cost
3. Termination protection for EC2 instance is turned off by default,you must turn it on.
4. On an EBS backed instance ,the default action is for the root EBS volume to be deleted when the instance is terminated.
5. EBS root voulmes of your default AMI's cannot be encrypted.You can use third party tools (such as bit locker etc) to encrypt the root volume,or this can be done when creating AMIs in the AWS console or using the API.  		
6. Additional EBS volumes can be encrypted.
7. Commands to mount and unmount EBS volumes
	7.1 Login to the linux ec2 instance using ssh
	7.2 sudo su
	7.3 lsblk
	7.4 mkfs -t ext4 /dev/xvdf
	7.5 mkdir <<directoryname>>	
	7.6 mount /dev/xvdf /durgi
	7.7 lsblk
	7.8 cd /
	7.9 umount /dev/xvdf
8. Steps to upgrade the EBS volume attached to EC2
	8.1 Unmount the volume 
	8.2 Detach the volume
	8.3 Create snapshot from the detached volume
	8.4 Create new volume from the snapshot created.Upgrade the volume type
	8.5 Attach the newly created volume to EC2
	8.6 Mount the volume.
	8.7 Hence the data in the already attached volume is retained and the type of vol/ume is also upgraded 	
9. Meta data URL 
		http://169.254.169.254/latest/meta-data/

10. Bash Script
		* #!/bin/bash
		* yum update -y
		* sudo su
		* yum install httpd -y
		* service httpd start
		* chkconfig httpd on
		* cd /home/www/html
		* aws s3 cp s3://durgeshlingarkar-dr/welcome.html index.html

11. EC2 Instances Type
	11.1 D for Density.Speciality is Dense Storage.Use Case is Fileservers/Data Warehousing/Hadoop
	11.2 R for RAM.Speciality is Memory optimized.Use Case is Memory Intensive Apps/DBs 
	11.3 M for Main choice for general purpose apps.Speciality is General Purpose.Usecase is Application Servers
	11.4 C for compute.Speciality is Compute Optimized.CPU intensive Apps/DBs
	11.5 G for graphics.Speciality is graphics intensive.Usecase is Video Encoding/3D Application Streaming
	11.6 I for IOPS.Speciality is High Speed Storage.Usecase is NoSQL DBs,Data Warehousing etc
	11.7 F for FPGA.Speciality is Field Programmable Gate Array.Use case is hardware acceleration for you code.
	11.8 T for cheap general purpose (t2 micro).Speciality is lowest cost general purpose.Use case is webserver/Small DBs
	11.9 P - Graphics (Think pics).Speciality is graphics/general purpose GPU.Use Case is Machine Learning , Bitcoin mining etc.
	11.10 X -  Extreme memory.Speciality is memory optimized.Usecase is SAP HANA/Apache Spark etc


12. AMI's are regional.You can only launch an AMI from the region in which it is stored.However u can copy the AMI's to other regions using the console, command line or the amazon EC2 API. 

Note- Go through EC2 FAQ


EBS Service :- 
	1. Block based storage volumes
	2. It can be attached to EC2 instances
	3. EBS are placed in specific AZ
	4. Automatically replicated to protect from failure.Note that they are not backed up in diff AZ but in same AZ
	5. EBS Types
		5.1 Genral Purpose SSD (GP2)
			5.1.1 Used for balancing price and performace.
			5.1.2 3 IOPS per GD with upto 10000 IOPS.Can burst upto 3000 IOPS
		5.2 Provisioned IOPS SSD
			5.1.2 Used for I/O intensive applications like large relational databases
			5.1.3 Shoud be used if needed more then 10000 IOPS
			5.1.4 Can provision upto 20000 IOPS per volume
		5.3 Throughput Optimized HDD (ST1)
			5.3.1 Used for big data,data warehousing, log procesing
			5.3.2 Throughput Optimized HDD cannot be a boot volume.
		5.4 Cold HDD (SC1)
			5.4.1 Lowest cost storage for infrequent access
			5.4.2 Typical usecase is fileserver
			5.4.3 Cold HDD cannot be boot volumes
		5.5 Magnetic (Standard)
			5.5.1 Lowest cost per giga byte of ALL EBS volume types that is bootable.
			5.5.2 Ideal for workloads where data is access infrequently and lowest storage is imp
			5.5.3 More or less same as Cold HDD (SC1).The only diff is that it can be used as a boot volume.
	6. You cannot mount one EBS volumne to multiple EC2 instances.For that u have to use EFS(Elastic File System)
	7. On termination of EC2 instance the associated EBS is deleted by default.We can configure it to not to do so while launching EC2.
	8. EBS volumes can be changed on the fly (except for the magnetic standard)
	9. Best practice is to stop the ec2 instance and then change the volume
	10. If you change the volumne on the fly you must wait for 67 hours before making any changes.
	11. U have to scale EBS volumes up only 
	12. Volumes must be in the same AZ as that of EC2 instances 
	13. To create a snapshot for amazon EBS volumes that serves as root devices , you should  stop the instance before taking the snapshot.
	14. Snapshots of encrypted volumes are encrypted automatically.
	15. Volumes restored from encrypted snapshots are encrypted automatically.
	16. You can share snapshots in market place only if they are not encrypted as the encrytion key is tied to ur AWS account.
	17. The unencrypted snapshots can be shared with other AWS accounts or made public.
	18 EBS Volumes vs Instance Store Volumes
		18.1 All AMIs are categorized as either backed by AMAZON EBS or backed by instance store.
		18.2 For EBS volumes ,The root device for an instance launched from the AMI is an Amazon EBS volume created from an amazon EBS snapshot.
		18.3 For Instance Store Volumes,  The root device for an instance launched from the AMI is an instance store volumne created from a template stored in  Amazon S3.
		18.4 Instance store volumes are sometimes called as Ephemeral Storage.
		18.5 Instance store volumes cannot be stopped , if the underying host fails , you ll lose your data.
		18.6 EBS backed instances can be stopped , You ll not lose the data on this instance if it is stopped.
		18.7 You can reboot both instance store and EBS backed , You ll not lose your data.
		18.8 With instance store ,by default the root volumes ll be deleted on termination.However, with EBS volumes you can tell AWS to keep the root device volume.
	19. Volumes vs Snapshots
		19.1 Volumes exist on EBS (i.e on virtual hard disks)
		19.2 Snaphot exist on S3.
		19.3 You can take snapshots of a volume ,this ll store that volumne on S3.
		19.4 Snapshots are point in time copies of volumes.
		19.5 Snapshots are incremental, this means that only the blocks that have changed since your last snapshot are moved to S3.Hence it takes time to create the first snapshot as against the subsequent snapshots that ll be generated.
		19.6 Snapshots of encrypted volumes are encrypted automatically.
		19.7 Volumes restored from encrypted snapshots are encrypted automatically.
		19.8 You can share snapshots in market place, but only if they are unencrypted. 




*************************************************************************************************************************************************

VPC 

1. Amazon Virtual Private Cloud lets u provision a logically isolated section of the Amazon web services cloud where you can launch AWS resources in virtual network that you define.You have complete control over your virtual networking environment, including selection of your IP address range , creation of subnets , and configuration of route tables and network gateways.
2. You can easily customize the network configuration for you Amazon Virtual Private Cloud.For example, you can create a public facing subnet for your webservers that has access to the internet, and place your backend systems such as databases or application servers in a private facing subnet with no internet access.You can also leverage multiple layers of security, including security groups and network access control lists, to help control to Amazon EC2 instances in each subnet.
3. Additionally, you can create a Hardware Virtual Private Network (VPN) connection between your corporate datacenter and your VPC and leverage the AWS cloud as an extension of your corporate datacenter.This setup is also called as hybrid cloud 
4. What can you do with VPC
	4.1 Launch instances into a subnet of your choosing
	4.2 Assign custom IP address ranges for each subnet.
	4.3 Configure route tables between subnets
	4.4 Create an Internet Gateway and attach it to your VPC.
	4.5 Much better security control over your AWS resources.
	4.6 Create security groups for instances
	4.7 Subnet network access control lists(ACLS)
5. Default VPC
	5.1 Default VPC is user friendly , allowing you to immediately deploy instances.
	5.2 All subents in default VPC have a route out to the internet.
	5.3 Each EC2 instance have both a public and private IP address.
	5.4 If u delete the default VPC the only way to get it back is to contact AWS.
6. VPC Peering
	6.1 Allows you to connect one VPC with another via a direct network route using private IP addresses.
	6.2 Instances behave as if they are om the same private network.
	6.3 You can peer VPC's with other AWS accounts as well as with other VPCs in the same account.
	6.4 Peering is in a star configuration, i.e 1 central VPC peers with 4 others. No Transitive Peering (i.e one VPC cannot talk to other VPC via a third VPC)
7. Think of a VPC as logical datacenter in AWS	
8. It consists of IGW's (Internet Gateway or Virtual Private Gateways), Route Tables, Network Access Control Lists, Subnets, Security Groups.
9. One VPC can only have one Internet Gateway.You cannot configure multiple internet gateways to a VPC.
10. One subnet is equal to one AZ.One subnet cannot span across multiple AZs
11. Security Groups are statefull , Network Access Control Lists are stateless
12. There is no Transitive Peering in a VPC.
13. When you create a VPC then Route Tables, Security Groups and Network Access Control Lists are automatically created.
14. NAT Instances
	14.1 When creating a NAT instance, Disable Source/Destination check on instance.
	14.2 NAT instance must be in a public subnet.Once subnet is equal to one AZ.So NAT is always in one AZ.
	14.3 There must be a route out of the private subnet to the NAT instance, in order for this to work.
	14.4 The amount of traffic that a NAT instance supports, depends on the instance size.If you are bottlenecking, increase the instance size.
	14.5 You can create high availability using AutoScaling Groups, Multiple Subnets in different AZs and a script to automate failover.
	14.6 NAT instances are always behind a security group.
15. NAT Gateways
	15.1 NAT gateways are very new.
	15.2 Preffered by the enterprise.
	15.3 Scale automatically up to 10gbps
	15.4 No need to patch.
	15.5 Not associated with security groups.
	15.6 Automatically assigned a public  IP address
	15.7 Remember to update your route table.
	15.8 No need to disable Source/Destination checks.
16. Read NAT Instances vs NAT Gateways in AWS docuentation
17. Security Groups vs Network ACL
	17.1 Security group operates at instance level (first layer of defence) where as Network ACL operates at subnet level (Second Layer of Defence)
	17.2 Security groups supports allow rules only where as Network ACL supports allow rules and deny rules.
	17.3 SGs are steteful (i.e Return traffic is automatically allowed, regardless of any rules) where as Network ACL is stateless (i.e return traffic must be explicitly allowed by rules)	
	17.4 SGs evaluate all rules before deciding whether to allow traffic whereas Network ACL process rules in number order when deciding whether to allow traffic.
	17.5 SGs applies to an instance only if someone specifies the security group when launching the instance, or associate the security group with the instance later on. whereas Network ACL automatically applies to all instances in the subnets it's associated with (backup layer of defence, so you dont have to rely on someone specifying the security group.)
18. Network ACL
	18.1 Your VPC automatically comes with a default Network ACL and by default it allows all outbound and inbound traffic.
	18.2 You can create custom Network ACL.By Default, each custom network ACL denies all inbound and outbound traffic untill you add rules.
	18.3 Each subnet in your VPC must be associated with a network ACL.If you dont explicitly associate a subnet with a Network ACL, the subnet is automatically associated with the default network ACL.
	18.4 You can associate a Network ACL with multiple subnets.However, a subnet can be associated with only one Network ACL at a time.When you associate a network ACL with a subnet, the previous assiciation of the subnet is removed.
	18.5 A network ACL contains a numbered list of rules that is evaluated in order , starting with the lowest numbered rule.
	18.6 A network ACL has separate inbound and outbound rules, and each rule can either allow or deny traffic.
	18.7 Network ACLs are stateless.i.e responses to allowed inbound traffic are subject to the rules for outbound traffic and vice versa.
	18.8 You can block specific IP addresses using network ACLs and not security groups.
19 NAT VS Bastion
	19.1 A NAT is used to provide internet traffic to EC2 instances in private subnets whereas a Bastion is used to securely administer EC2 instances (using SSH or RDP) in private subnets. 
20. Five VPCs are allowed in each AWS region by default.

	



*************************************************************************************************************************************************
Security Groups

1. In security groups as soon as u add inbound rule , the respective outbound rule is added irrespective of explicit configuration of outbound rule.Whatever is allowed in it is allowed out as well.This means security groups stateful means if u add inboud rule it automatically adds outbound rule
2.All inbound traffic is blocked by default
3.All outbound traffic is allowed by default
4. Changes to security groups takes effects immediately
5.You can any number of EC2 instances within a security group.
6. You can have multiple security groups attached to EC2 instances
7. Security groups are stateful.It means if u create an inbound rule allowing traffic in , the traffic is automatically allowed back again
8. You cannot block specific IP addresses using security groups , instead use Network access control lists
9. You can specify allow rules but cannot deny rules



*************************************************************************************************************************************************
RAID & Snapshot

1. RAID - Stands for Redundant Array of Independent Disk.It means putting bunch of disks together which act as a single disk to the OS
2. Types of RAID
	2.1 RAID 0 - Striped, No Redundancy , Good Performance
	2.2 RAID 1 - Mirrorred, Redundancy
	2.3 RAID 5 - Good for reads ,bad for writes , AWS does not recommend ever putting RAID 5 on EBS
	2.4 RAID 10 - Stripped and Mirrorred , Good Redundancy and Good Performance.
3. Problem in taking snapshot of RAID Array - The snapshot excludes the data held in cache by the applications or the OS.This does not matter wen there is a single volumne.However, in a RAID setup there are multiple volumes with interdependacies which poses a problem
4. How to take a snapshot of a RAID array
	4.1 Stop the application from writing to disk
	4.2 Flush all caches to the disk
5. How to achieve the soutions mentioned in point 4
	5.1 Freeze the file system
	5.2 Unmount the RAID array
	5.3 Stopping the associated EC2 instance  (This is the most easiest of all)	


*************************************************************************************************************************************************
ELB (Elastic Load Balancer) Service - 

1. Instances managed by ELB are reported as InServie or OutOfService
2. Health check checks the instances health by talking to it.
3. ELB have their own DNS name.You are never given an IP address for ELB
4. Read FAQ for classic ELB 


*************************************************************************************************************************************************

Cloud Watch

1. Standard monitoring is 5 mins
2. Detailed monitoring is 1 min
3. With cloud watch u can create dashboards to see what is happening with ur AWS environment
4. Allows u to set alarms that notify you when particular thresholds are hit.Also these alarms are used for auto scaling
5. Cloudwatch events helps u to respond to state changes in AWS resources
6. Cloud watch logs helps u to aggregate , monitor and store logs
7. Cloudwatch is for logging and monitoring resources whereas cloudtrail is for auditing.


*************************************************************************************************************************************************

Placement group
	1. A placement group is a logical grouping of instances within a single availability zone.Using placement groups enables applications to participate in a low latency ,10 Gbps network.Placement groups are recommended for applications that benefit from low network latency, high network throughput , or both
	2. A placement group cant span across multiple AZs
	3. The name u specify to ur placememt group must be unique within ur AWS account.
	4. Only certain types of instances can be launched in placement group (Compute optimized,GPU,Memory optimized,Storage optimized)
	5. AWS recommend homogenous instances (means instances of same size and same family) within placement group
	6. You cant merge placement groups
	7. You cant move an exiting instance in a placement group.You can create an AMI from your existing instance, and then launch a new instance from the AMI into a placement group. 

*************************************************************************************************************************************************

EFS (Elastic File System)

1. Amazon Elastic File System is File storage service for Amazon EC2.
2. EFS is easy to use and provides simple interface that allows u to create and configure file systems easily and quickly.
3. With EFS,storage capacity is elastic , growing and shrinking automatically as u add and remove files, so ur applications have the storage they need, when they need it.
4. We cannot mount one EBS volume to 2 or more EC2 instances , thats exactly what EFS allows us to do.
5. EFS supports Network File System version 4 (NFSv4) protocol.
6. You only pay for the storage u use (it means no pre provisioning is required) unlike EBS.
7. EFS can scale up to petabytes
8. EFS can support thousands of concurrent NFS connections
9. Data is stored across multiple AZs within a region.
10. EFS is block based storge as opposed to object based storage like the one in S3.We can put files in EFS and share it with other EC2 instances.
11. EFS has read after write consistency just like S3. 	
12. EFS usecase is, it is used as a file server.it acts as a shared repository whose files are accessed  by multiple EC2s.

*************************************************************************************************************************************************
LAMDA

1 LAMDA encapsulates 
	1.1 Data centers
	1.2 Hardware
	1.3 Assembly code/Protocols
	1.4 High Level Languages
	1.5 Operating Systems
	1.6 Application Layer/AWS APIs
	1.7 AWS LAMDA

2. AWS LAMDA is a compute service where you can upload your code and create a LAMDA function.AWS LAMDA takes care of provisioning and managing the servers that you use to run the code.You dont have to worry aboubt operating systems,patching , scaling etc.You can  use LAMDA in the following ways.
	2.1 As an event driven compute service where AWS LAMDA runs code in response to the events.These events could be changes to data in an AMAZON S3 bucket or an AMAZON  DynamoDB table.
	2.2 As a compute service to run your code in response to HTTP requests using AMAZON API gateway or API calls made using AWS SDKs.

3. Following are the triggers for LAMDA
	3.1 API Gateway
	3.2 AWS IOT
	3.3 ALEXA Skill kits
	3.4 ALEXA Smart Homes
	3.5 CloudFront
	3.6 Cloudwatch Events
	3.7 Cloudwatch Logs
	3.8 CodeCommit
	3.9 Cognito Sync Trigger
	3.10 DynamoDB
	3.11 Kinesis
	3.12 S3
	3.13 SNS

4. Languages supported by LAMDA
	4.1 Node.js
	4.2 JAVA
	4.3 Python
	4.4 C#

5. LAMDA Pricing
	5.1 LAMDA is priced based on number of request
		5.1.2 Fisrt 1 million request are free. $0.20 per 1 million requests thereafter.
	5.2 LAMDA is priced based on the Duration
		5.2.1 Duration is calculated from the time your code begins executing until it returns or otherwise terminates , rounded up to the nearest 100ms.
		5.2.2 The price depends on the amount of memory allocated to your function.You are charged $0.00001667 for every GB-second used.

6. Why is LAMDA cool
	6.1 No servers
	6.2 Continous scaling
	6.3 Very cheap

7. LAMDA scales out (not scale up) automatically

8. LAMDA functions are independent, 1 event = 1 function

9. LAMDA is serverless

10. LAMDA functions can trigger other LAMDA functions , 1 event can trigger X number of lamda fuctions which in turn can trigger other LAMDA functions.

11. Architectures can get extremely complicated with mutiple LAMDA functions, Debugging can be a nightmare. AWS X-rays allows you to debug what is happening

12. LAMDA can do things globally , You can use it to backup S3 buckets to other S3 buckets etc.

13. LAMDA's duration time is maximum of 5 mins.Post which the execution is terminated or timed out.

*************************************************************************************************************************************************
IAM

1. Roles
	1.1 Role are more secure than storing you access key and secret access key on individual EC2 instances.
	1.2 Roles are easier to manage.
	1.3 Roles can be assigned to an EC2 instance after it has been provisioned using both the command line the AWS console.
	1.4 Roles are universal.You can use them in any region
	1.5 


*************************************************************************************************************************************************
Gateway API

1. Cross origin resource sharing (CORS)
	It enables you to invoke ur API URL from a website that has different host name.


*************************************************************************************************************************************************

Route53 - It is a global service and not region specific


1. ELB's do not have predefined IPv4 addresses, you resolve to them using a DNS name.Hence there is a problem suppose u have acloud.guru which is a naked domain name , u ll always need an IPv4 address.To solve this issue amazon created Alias Record.Alias record allows u to resolve to a naked domain name somtimes refered to as zone apex record to a ELBs DNS address.
2. When u make a request through route53 using CNAME you are goin to be charged for that request.But if ur making a request through route53 using Alias records then u wont be charged.Hence given the choice , always choose Alias records over CNAME
3. The last word in the domain name reprents "top level domain" and the second word in the domain name is know as "Second level domain". Eg  in .co.uk , "uk" is top level domain and "co" is second level domain
4. You can get the domain names at following URL. http://www.iana.org/domains/root/db
5. A Records
	- An "A" record is the fundamental type of DNS record and the "A" in A record stands for "Address". The A record is used by computer to translate the name of the domain to the IP address.For eg:- http://www.acloudguru.com might point to http://123.10.10.80
6. TTL
	- The length that a DNS record is cached on either the resolving server or the users own local PC is equal to the value of the "Time To Live" (TTL) in seconds.The lower the time to live, the faster changes to DNS records take to propagate throught the internet.
7. CNAME
	- A Canonical Name (CNAME) can be used to resolve one domain name to another.For example, you may have a mobile website with the domain name http://m.acloudguru.com that is used for when users browse to your domain name on mobile devices.You may want the name http://mobile.acloudguru.com to resolve to this same address.
8. Routing Policy
	8.1 Simple Routing Policy
		8.1.1 This is the default routing policy when u create a new record set.This is most commonly used when you have a single resource that performs a given function for your domain, for example, one web server that serves the content.
		
	8.2 Weighted Routing Policy
		8.2.1 This policy let you split your traffic based on different weights assigned.For eg. You can set 10% of your traffic to go to US-EAST-1 and 90% to go to EU-WEST-1

	8.3 Latency Routing Policy
		8.3.1 Latency based routing allows you to route your traffic based on the lowest network latency for you end user(i.e which region ll give them the fastest response time).
		8.3.2 To use latency based routing you create a latency resource record set for the amazon EC2 (or ELB) resource in each region that hosts your website.When Amazon Route 53 receives a query for your site, it selects the latency resource record set for the region that gives the user the lowest latency. Route53 then responds with the value associated with that resource record set.


	8.4 Failover Routing Policy
		8.4.1 Failover routing policies are used when you want to create and active/passive setup.For example you may want your primary site to be in EU-WEST-2 london region and ur secondary DR site in AP-SOUTHEAST-2 sydney region.
		8.4.2 Route53 ll monitor the health of your primary site using a health check.A heath check monitors the health of your endpoints.
		8.4.3 If the health check fails , then the traffic is routed to your DR site by Route53. 

	8.5 Geolocation Routing Policy
		8.5.1 Geolocation routing lets you choose where your traffic will be sent based on the geographic location of your users(i.e the location from which the DNS queries originate). For Eg:- You might want all queries from Europe to be  routed to a fleet of EC2 instances that are specifically configured for your european customers.These servers may have the local language of your European customers and all prices are displayed in EUROS.

	8.6 Route53 does support MX (Mail Exchange) records 
	
	8.7 There is a limit of 50 domain names u can have using Route53, however this limit can be raised by contacting AWS support.


************************************************************************************************************************************************

RDS Service 

1. Relational Databases under RDS
	1.1.1 SQL server
	1.1.2 Oracle
	1.1.3 MySQL Server
	1.1.4 PostgreSQL
	1.1.5 Aurora
	1.1.6 MariaDB

2. Non Relational Databases/NoSQL Databases under RDS
	1.1 DynamoDB

3. RedShift 
	1. It is for datawarehousing or OLAP service.


4. Elastic Cache
	4.1 Elastic cache is a web service that makes it easy to deploy, operate and scale an in memory cache in cloud.The service improves the performance of web applications by allowing you to retrieve information from fast,managed in memory caches , instead of relying entirely on slower disk based databses.
	4.2 Elastic cache supports 2 open source in memory caching engines 
		4.2.1 Memcached
		4.2.2 Redis
5. DMS (Database Migration service)
	5.1 Allows u to migrate ur production database to AWS.Once the migration has started,AWS manages all the complexities of the migration processes like data type transforation, compression, and parallel transfer(for faster data transfer) while ensuring that data changes to the source database that occur during the migration process are automatically replicated to the target.
	5.2 AWS schema conversion tool automatically converts the source database schema and a majority of the custom code , including views ,stored procedures and functions to a format compatiable with the target database.	 		

6. Datawarehousing vs RDS / OLTP vs OLAP 
	6.1 OLTP didders from OLAP in terms of the typs of queries they run.
	6.2 OLTP eg :- get details of order 1001.Pulls up the row of data name , date , address,delivery status etc.
	6.3 OLAP eg:- Net profit for EMEA and pacific for the digital radio product.Pulls in the large number of records and does operations like summation

7. RDS Backups
	7.1 Automated Backups
		7.1.1 There are 2 diff types of backups for AWS.Automated Backups and Database Snapshots.
		7.1.2 Automated backups allow you to recover your database to any point in time within a "retention period".Retention period can be between 1 and 35 days.Automated backups ll take a full daily snapshot and ll also store transaction logs throught the day.When u do a recovery, AWS ll choose the most recent daily backup, and  then apply transaction logs relevant to that day.This allows you to do a point in time recovery down to a second, within a retention period.
		7.1.3 Automated backups are endbaled by default.This backup data is stored in S3 and you get a free storage space equal to the size of your database.So if you have a RDS instance of 10GB you ll get 10GB worth of storage.
		7.1.4 Backups are taken within a defined window.During the backup window, storage I/O may be suspended while your data is being backed up and you may experience elavated latency.

	7.2 Snapshots
		7.2.1 DB snapshots are done manually (i.e initiated by user).They are stored even after you delete the original RDS instance, unlike automated backups.

	7.3 Whenever you restore either an Automatic Backup or a manual snapshot , the restored version of the database will be a new RDS instance with an new end point.
	
8 Encryption
	8.1 Encryption at rest is supported for MySQL, Oralce, SQL server,PostgreSQL & MariaDB. Encryption is done using AWS Key Management System (KMS) service.Once you RDS instance is encrypted the data stored at rest in the underlying storage is encrypted , as are its automated backups ,read replicas and snapshots.
	8.2 At present time, encrypting an existing DB instance is not supported.To use amazon RDS encryption for an existing database, create a new DB instance with encryption enabled and migrate your data into it.


9 Multi AZ RDS
	9.1 Multi AZ allows u to have an exact copy of your production database in another AZ.AWS haldles the replication for you, so when your production database is written to, this write ll automatically be synchronised to the stand by  database.
	9.2 In the event of planned database maintainance, DB instance failure, or an AZ failure, Amanzon RDS ll automatically failover to the standby so that database operations can resume quickly without administrative intervention.
	9.3 Multi AZ is for  disaster recovery only.It is not primarily used for performance improvement.For performance improvement you need read replicas.
	9.4 Multi AZ Databases are applicable for
		9.4.1 SQL Server
		9.4.2 Oracle
		9.4.3 MySQL Server
		9.4.4 PostgreSQL
		9.4.5 MariaDB

10 Read Replica
	10.1 Read replica allows you to have a read only copy of your production database.This is achieved by using asynchronous replication from the primary RDS instance to the read replica.You can use read replica's primarily for very read-heavy database workloads.
	10.2 Read Replicas are supported in 
		10.2.1 MySQL Server
		10.2.2 PostgreSQL
		10.2.3 MariaDB
	10.3 Read replicas are used for scaling and not for DR
	10.4 Must have automatic backups turned on in order to deploy a read replica.
	10.5 You can have upto 5 red replicas copy of any database
	10.6 You can have read replicas of read replicas (but watch out for latency)	
	10.7 Each read replicas is gonna have its own DNS end point.
	10.8 You cannot have Read Replicas that have Multi AZ.
	10.9 You can create read replicas of multi AZ source databases however.
	10.10 Read replicas can be promoted to be their own databases.This breaks the replication.
	10.11 You can also have read replicas in a second region for MySQL and MariaDB.Not for PostgreSQL.

 Note :- Read FAQs of RDS service.

11. DynamoDB vs RDS
	11.1 DynamoDB offers "push button" scaling , meaning that u can scale your database on the fly , without any down time.
	11.2 RDS is not so easy and you usually have to use a bigger instance size or to add a replica.
	11.3 In RDS you can scale up but scale out is only possible in case of reads and not writes.

12. DynamoDB
	12.1 Amazon DynamoDB is fast and flexible NoSQL database service for all applications that need consistent, single digit latency at any scale.It is a fully managed database and supports both document and key value data models.Its flexile data model and reliable performance make it a great fit for mobile,web,gaming ,ad-tech,IOT and many other applications.
	12.2 DynamoDB is always stored on SSD storage.
	12.3 DynamoDB is spread across 3 geographically distinct data centres.
	12.4 DynamoDB has eventual consistent reads by default.
		12.4.1 Consistancy across all copies of data is usually reached within a second.Repeating a read after a short time should return the updated data. (This is a best model for Read Performance)	
	12.5 DynamoDB also supports Strongly Consistent Reads
		12.5.1 A strongly consistent read returns a result that reflect all writes that received a succesful response prior to the read.		
	12.6 Pricing
		12.6.1 Provisioned ThroughPut Capacity
			12.6.1.1 Write throughput $0.0065 per hour for every 10 units.
			12.6.1.2 Read throughput $0.0065 per hour for every 50 units
		12.6.2 Storage cost of $0.25 Per GB per month.
		12.6.3 Pricing Example
				12.6.3.1 Lets assume that ur application needs to perform 1 million writes and 1 million reads per day, while storing 3GB of data.First u need to calculate how many writes and reads per second you need.
				12.6.3.2 One million evenly spread writes per day is equivalent to 1000000(writes)/24(hours)/60(minute)/60(seconds)=11.6 write per second.
				12.6.3.3 A DynamoDB capacity unit can handle 1 write per second, so you need 12 write capacity units.
				12.6.3.4 Similarly, to handle 1 million strongly Consistent reads per day , you need 12 read capacity units.
				12.6.3.5 With Read capacity units, you are billed in blocks of 50.With write capacity units, You are billed in blocks of 10.
				12.6.3.6 To calculate Write capacity units (0.0065/10)*12*24=$1872
				12.3.6.7 To calculate Read Capacity units = (0.0065/50)*12*24=$0.0374		 							

13. RedShift
	13.1 Amazon RedShift is a fast and powerful, fully managed, Petabyte-scale data warehouse service in the cloud.Customers can start small for just $0.25 per hour with no commitments or upfront costs and scale to a petabyte or more for $1000 per terabyte per year, less than a tenth of most other dataware housing solutions.
	13.2 Redshift is used for OLAP operations.  
	13.3 Redshift Configuration
		13.3.1 Single Node - Upto 160 GB
		13.3.2 Multi Node - If you want to scale more than 160 GB use multi node.
			13.3.2.1 Leader Node - Manages client connections and received queries
			13.3.2.2 Compute Node - Stores data and performs queries and computations.You can have upto 128 compute nodes.
	13.4 Redshift has columnar data storage - Instead of storing data as a series of rows, Amazon Redshift organizes the data by column.Unlike row based system, which are ideal for transaction processing, column based systems are ideal for data warehousing and analytics, where queris often involve aggregates performed over large datasets. Since only the columns involved in the queries are processed and columnar data is stored sequentially on the storage media, column based systems require far fewer I/Os, greatly inproving query performance.
	13.5 Redshift has Advanced Compression - Columnar data stores can be compressed much more than row based data stores because similar data is stored sequentially on disk.Amazon redshift employs multiple compression techniques and can often achieve significant compression relative to traditional relational data stores.In Addition, Amazon Redshift doesnt requires indexes or materialized views and so use less space than traditional relational database systems.When loading data into an empty table, Amazon Redshift automatically samples your data and selects the most appropriate compression scheme.
	13.5 Redshift has Massively Parallel Processing (MPP) - Amazon Redshift automatically distributes data and query across all nodes.Amazon redshift makes it easy to add nodes to your data warehouse and enables you to maintain fast query performance as your data warehouse grows.
	13.6 Redshift Pricing
		13.6.1 Compute node hours - Total number of hours you run across all your compute nodes for the billing period.You are billed for 1 unit per node per hour, so a 3-node data warehouse cluster running persistingly for an entire month would incur 2160 instance hours.You ll not be charged for leader node hour.Only compute nodes ll incur charges.
		13.6.2 Backup - You are charges for BackUp
		13.6.3 Data Transfer - You are charged for data transfer (but only within a VPC not outside it)
	13.7 Redshift Security
		13.7.1 Encrypted in transit using SSL
		13.7.2 Encrypted at rest using AES-256 encryption
		13.7.3 By default Redshift takes care of key management.However you can manage your keys through HSM (Hardware Security Module) or through AWS Key Management Service.
	13.8 Redshift Availability
		13.8.1 Currently only available in 1AZ
		13.8.2 You can restore snapshots of Redshift to new AZs in the event of an outage.

14. Elasticache
	14.1 Elasticache is a webservice that makes it easy to deploy, operate and scale an in memory cache in the cloud.The service improves the performance of web applications by allowing you to retrieve information from fast, managed, in memory caches instead of relying entirely on slow disk based databases.
	14.2 Caching improves application performance by storing critical pieces of data in memory for low latency access.Cached information may include the results of I/O intensive database queries or the results of the computationally intensive calculations.
	14.3 Types of ElastiCache
		14.3.1 MemCached
			14.3.1.1 A widely adopted memory object caching system.Elasticache is protocol compliant with Memcached, so popular tools that u use today with existing Memcached environments will work seamlessly with the service.
		14.3.2 Redis
			14.3.2.1 A popular open source in memory key-value store that supports data structures such as sorted set and lists.Elasticache supports Master/Slave replication and multi AZ which can be used to achieve cross AZ redundancy.
	14.4 Scenario - Typically u ll be given a scenario where a particular database is under a lot of stress/load. You ll be asked which service you should use to alleviate this.
		14.4.1 Elasticache is good choice if ur database is particularly read heavy and not prone to frequent changes.
		14.4.2 Redshift is good if the reason your database is feeling stress is because management keep running OLAP transactions on it etc.

15. Aurora
	15.1 Amazon Aurora is a MySQL-Compatiable, relational database engine that combines the speed and availability of high end commercial databases with the simplicity and cost effectiveness of an open source databases.Amazon Aurora provides upto five time better performance than MySQL at a price point one tenth of that of a commercial database while delivering similar performance and availability.
	15.2 Scaling 
		15.2.1 Start with 10GB, scales in 10GB increments to 64TB (Storage AutoScaling)
		15.2.2 Compute resources can scale up to 32vCPUs and 244GB of memory.
	15.3 Two copies of ur data is contained in each availability zone, with minimum of 3 availability zones.6 copies of your data is maintained.
	15.4 Aurora is designed to transparently handle the loss of up to 2 copies of data without affecting database write availability and upto 3 copies without affecting read availability.
	15.5 Aurora storage is also self healing.Data blocks and disks are continously scanned for erros and repaired automatically.

16. By default, the maximum provisioned IOPS capacity on an Oracle and MySQL RDS instance (using provisioned IOPS) is 30,000 IOPS.

17. When replicating data from your primary RDS instance to your secondary RDS instance, the data transfer is free of any charge.

18. When you add a rule to an RDS security group you do  need to specify a port number or protocol

19. If you are using Amazon RDS Provisioned IOPS storage with MySQL and Oracle database engines, the maximum size RDS volume you can have by default is 6TB

20. By default, the maximum provisioned IOPS capacity on an Oracle and MySQL RDS instance (using provisioned IOPS) is 30,000 IOPS.


*************************************************************************************************************************************************

SQS (Simple Queue Service)
1. SQS was the first ever AWS service that was publicly available and hence the oldest service. 
2. Amazon SQS is web service that gives you access to a message queue that can be used to store messages while waiting for a computer to process them.Amazon SQS is a distributed queue system that enables web service applications to quickly and reliably queue messages that one component in the application generates to be consumed by another component.A queue is a temporary repository for messages that are waiting for processing.
3. Using SQS you can decouple the components of an application so they run independently, with amazon SQS easing message management between components.Any component of a distributed application can store messages in fail-safe queue.Messages can contain upto 256KB of text in any format.Any component can later retrieve the messages programatically using the SQS API.
4.The queue acts as a buffer between the component producing and saving data, and the component receiving the data for processing.This means the queue resolves the issues that arises if the producer is producing work faster than the consumer can process it, or if the producer or consumer are only intermittenly connected to network.
5. Types of Queue in SQS
	5.1 Standard Queues (default)
		5.1.1 Amazon SQL offers standard as the default queue type.A standard queue lets you have nearly unlimited number of transactions per second.Standard queues gaurantee that the message is delivered atleast once.However, ocassionally(because of the highly distributed architecture that allows high throughput ), more than one copy of the message might be delivered out of order.Standard queue provide best effort ordering which ensures that messges are generally delivered in the same order as they are sent.
	5.2 FIFO Queues
		5.2.1 The FIFI queue complements the standard queue.The most important feature of this queue type are FIFO delivery and exactly once processing: The order in which messages are sent and received is strictly preserved and a message is delivered once and remains available until a consumer processes and deletes it.Duplicates are not introduced into the queue.FIFO queues also support message groups that allow multiple ordered message groups within a single queue.FIFO queues are limited to 300 transactions per second (TPS) , but have all the capabilities of standard queues. 	
6. SQS Keyfacts
	6.1 SQS is pull based not push based.
	6.2 Messages are 256KB in size.
	6.3 Messages can be kept in the queue from 1 minute to 14 days.The default is 4 days.
	6.4 Visibility Time out is the amount of time that the message is invisible in the SQS queue after the reader picks up the message.Provided the job is processed before the visibility time out expires, the message ll then be deleted from the queue.If the job is not processed within that time , the message ll become visible again and another reader ll process it.This could result in the same message being delivered twice.
	6.5 Maximum visibility timeout is 12 hours.
	6.6 SQS gaunrantees that your messages ll be processed atleast once.
	6.7 Amzon SQS long polling is a way to retrieve messages from your SQS queues.While the regular short polling returns immediately, even if the message queue being polled is empty, long polling doesnt return a response until a message arrives in the nessage queue or the long poll times out.Thus long polling is less expensive as compared to short polling as in short polling an EC2 continously polls the queue for messages.
						